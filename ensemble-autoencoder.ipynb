{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.9.6 64-bit"},"language_info":{"name":"python","version":"3.9.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":5,"source":["!pip install numpy"],"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /Volumes/UTILITIES/ANACONDA/anaconda3/lib/python3.8/site-packages (1.20.1)\n"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import os\n","import numpy as np\n","from scipy.cluster.hierarchy import dendrogram, to_tree\n","from sklearn.cluster import AgglomerativeClustering\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras import layers, losses, Sequential\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["- Nine IoT devices were used.\n","- The devices were 2 smart doorbells, 1 smart thermostat, 1 smart babymonitor, 4 security cameras and 1 webcam.\n","- Traffic was captured when the devices were in normal execution and after infection with malware.\n","- Mirai and BashLite (aka gafgyt) malware were used.\n","- From the network traffic, 115 features were extracted as described in [1]."],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["def load_nbaiot(filename):\n","    return np.genfromtxt(\n","        os.path.join(\"/kaggle/input/nbaiot-dataset\", filename),\n","        delimiter=\",\",\n","        skip_header=1\n","    )\n","benign = load_nbaiot(\"1.benign.csv\")\n","X_train = benign[:40000]\n","X_test0 = benign[40000:]\n","X_test1 = load_nbaiot(\"1.mirai.scan.csv\")\n","X_test2 = load_nbaiot(\"1.mirai.ack.csv\")\n","X_test3 = load_nbaiot(\"1.mirai.syn.csv\")\n","X_test4 = load_nbaiot(\"1.mirai.udp.csv\")\n","X_test5 = load_nbaiot(\"1.mirai.udpplain.csv\")"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:45:14.919231Z","iopub.execute_input":"2021-06-28T16:45:14.919631Z","iopub.status.idle":"2021-06-28T16:46:56.071148Z","shell.execute_reply.started":"2021-06-28T16:45:14.919588Z","shell.execute_reply":"2021-06-28T16:46:56.070290Z"},"trusted":true}},{"cell_type":"code","execution_count":3,"source":["print(X_train.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n","      X_test3.shape, X_test4.shape, X_test5.shape)"],"outputs":[{"output_type":"stream","name":"stdout","text":["(40000, 115) (9548, 115) (107685, 115) (102195, 115) (122573, 115) (237665, 115) (81982, 115)\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:46:56.072466Z","iopub.execute_input":"2021-06-28T16:46:56.072683Z","iopub.status.idle":"2021-06-28T16:46:56.078290Z","shell.execute_reply.started":"2021-06-28T16:46:56.072661Z","shell.execute_reply":"2021-06-28T16:46:56.077269Z"},"trusted":true}},{"cell_type":"code","execution_count":4,"source":["def agglomerative_clustering(data):\n","    # sqrt makes this a proper distance metric\n","    correlation_distance = np.sqrt(1-np.corrcoef(data.T))\n","    ac = AgglomerativeClustering(\n","        n_clusters=None,\n","        affinity=\"precomputed\",\n","        linkage=\"single\",\n","        distance_threshold=0\n","    )\n","    ac.fit(correlation_distance)\n","    return ac\n","\n","feature_mapping_phase = 7777\n","ac = agglomerative_clustering(X_train[:feature_mapping_phase])"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:46:56.079493Z","iopub.execute_input":"2021-06-28T16:46:56.079729Z","iopub.status.idle":"2021-06-28T16:46:56.107273Z","shell.execute_reply.started":"2021-06-28T16:46:56.079705Z","shell.execute_reply":"2021-06-28T16:46:56.106084Z"},"trusted":true}},{"cell_type":"code","execution_count":5,"source":["def linkage_matrix(model):\n","    counts = np.zeros(model.children_.shape[0])\n","    n_samples = len(model.labels_)\n","    for i, merge in enumerate(model.children_):\n","        current_count = 0\n","        for child_idx in merge:\n","            if child_idx < n_samples:\n","                current_count += 1  # leaf node\n","            else:\n","                current_count += counts[child_idx - n_samples]\n","        counts[i] = current_count\n","\n","    return np.column_stack([model.children_, model.distances_, counts]).astype(float)\n","\n","lm = linkage_matrix(ac)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:46:56.108713Z","iopub.execute_input":"2021-06-28T16:46:56.109089Z","iopub.status.idle":"2021-06-28T16:46:56.117758Z","shell.execute_reply.started":"2021-06-28T16:46:56.109050Z","shell.execute_reply":"2021-06-28T16:46:56.116725Z"},"trusted":true}},{"cell_type":"code","execution_count":6,"source":["import matplotlib.pyplot as plt\n","\n","dendrogram(lm)\n","plt.close(\"all\")"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:46:56.119462Z","iopub.execute_input":"2021-06-28T16:46:56.120016Z","iopub.status.idle":"2021-06-28T16:46:56.355780Z","shell.execute_reply.started":"2021-06-28T16:46:56.119972Z","shell.execute_reply":"2021-06-28T16:46:56.354850Z"},"trusted":true}},{"cell_type":"code","execution_count":7,"source":["def find_subsets(tree, max_cluster_size=10):\n","    if tree.count <= max_cluster_size:\n","        return [np.array(tree.pre_order())]\n","    recursion1 = find_subsets(tree.get_left(), max_cluster_size)\n","    recursion2 = find_subsets(tree.get_right(), max_cluster_size)\n","    return recursion1+recursion2\n","    \n","subsets = find_subsets(to_tree(lm))\n","\n","subsets"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([55, 62]),\n"," array([78, 75, 72, 66, 69]),\n"," array([14, 29, 11, 26,  8, 23,  2, 17,  5, 20]),\n"," array([48, 34, 41]),\n"," array([79, 76, 73, 67, 70]),\n"," array([50, 36, 43]),\n"," array([57]),\n"," array([101,  44,  71,  30,  65,  37,  68,  94,  80,  87]),\n"," array([ 64, 108,  51,  74,  58,  77,  53,  60]),\n"," array([46]),\n"," array([32, 39]),\n"," array([114]),\n"," array([63]),\n"," array([56]),\n"," array([110,  96, 103,  82,  89]),\n"," array([ 86,  35,  85,  93,  42,  92,  49,  99, 100]),\n"," array([ 84,  91,  98, 105, 112, 107, 106, 113]),\n"," array([47, 33, 40, 54, 61]),\n"," array([59]),\n"," array([52]),\n"," array([ 83,  90,  97, 104, 111]),\n"," array([ 7, 22]),\n"," array([ 1, 16,  4, 19]),\n"," array([ 45,  31,  38, 109,  81,  88,  95, 102]),\n"," array([10, 25, 13, 28]),\n"," array([12, 27,  9, 24,  6, 21,  0, 15,  3, 18])]"]},"metadata":{},"execution_count":7}],"metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:46:56.356888Z","iopub.execute_input":"2021-06-28T16:46:56.357143Z","iopub.status.idle":"2021-06-28T16:46:56.369236Z","shell.execute_reply.started":"2021-06-28T16:46:56.357119Z","shell.execute_reply":"2021-06-28T16:46:56.368173Z"},"trusted":true}},{"cell_type":"code","execution_count":8,"source":["class Autoencoder(Model):\n","    def __init__(self, n):\n","        super(Autoencoder, self).__init__()\n","        self.encoder = Sequential([\n","            layers.Dense(n, activation=\"relu\"),\n","            layers.Dense(int(0.75*n), activation=\"relu\"),\n","        ])\n","        self.decoder = layers.Dense(n, activation=\"relu\")\n","    \n","    def call(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return decoded\n","\n","def compile_and_train(ae, x):\n","    ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n","    ae.fit(\n","        x=x,\n","        y=x,\n","        # in reality, it is supposed to be an online algorithm, so\n","        # we make only 1 pass over the training data\n","        epochs=1\n","    )\n","\n","class Ensemble:\n","    def __init__(self, feature_subsets):\n","        self.map = feature_subsets\n","        self.scaler_ensemble = MinMaxScaler()\n","        self.scaler_output = MinMaxScaler()\n","        self.ensemble_layer = []\n","        for subset in feature_subsets:\n","            ae = Autoencoder(len(subset))\n","            self.ensemble_layer += [ae]\n","        self.output_layer = Autoencoder(len(feature_subsets))\n","        \n","    def train(self, data):\n","        scaled = self.scaler_ensemble.fit_transform(data)\n","        loss_ensemble = []\n","        \n","        for i, (features, ae) in enumerate(zip(self.map, self.ensemble_layer)):\n","            x = scaled[:, features]\n","            print(f\"##**~~__ Autoencoder {i+1}/{len(self.map)} for {len(features)} dimensions\")\n","            compile_and_train(ae, x)\n","            loss_ensemble += [losses.mse(x, ae(x))]\n","            \n","        # Because of the above loop, loss_ensemble now has shape\n","        # (n_autoencoders, n_samples). But for the output layer, the previous\n","        # layer outputs are actually treated as features. Therefore transpose\n","        loss_ensemble = self.scaler_output.fit_transform(np.array(loss_ensemble).T)\n","        print(f\"##**~~__ Output Autoencoder for {loss_ensemble.shape[1]} dimensions\")\n","        compile_and_train(self.output_layer, loss_ensemble)\n","        loss_out = losses.mse(loss_ensemble, self.output_layer(loss_ensemble))\n","        self.threshold = np.mean(loss_out)+np.std(loss_out)\n","    \n","    def predict(self, data):\n","        scaled = self.scaler_ensemble.transform(data)\n","        loss_ensemble = []\n","        \n","        for features, ae in zip(self.map, self.ensemble_layer):\n","            x = scaled[:, features]\n","            loss_ensemble += [losses.mse(x, ae(x))]\n","            \n","        loss_ensemble = self.scaler_output.transform(np.array(loss_ensemble).T)\n","        loss_out = losses.mse(loss_ensemble, self.output_layer(loss_ensemble))\n","        return loss_out > self.threshold"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:46:56.371021Z","iopub.execute_input":"2021-06-28T16:46:56.371273Z","iopub.status.idle":"2021-06-28T16:46:56.385186Z","shell.execute_reply.started":"2021-06-28T16:46:56.371247Z","shell.execute_reply":"2021-06-28T16:46:56.384229Z"},"trusted":true}},{"cell_type":"code","execution_count":9,"source":["ensemble = Ensemble(subsets)\n","ensemble.train(X_train[feature_mapping_phase:])"],"outputs":[{"output_type":"stream","name":"stdout","text":["##**~~__ Autoencoder 1/26 for 2 dimensions\n","1007/1007 [==============================] - 1s 763us/step - loss: 3.9535e-04\n","##**~~__ Autoencoder 2/26 for 5 dimensions\n","1007/1007 [==============================] - 1s 769us/step - loss: 8.1684e-04\n","##**~~__ Autoencoder 3/26 for 10 dimensions\n","1007/1007 [==============================] - 1s 780us/step - loss: 3.0822e-04\n","##**~~__ Autoencoder 4/26 for 3 dimensions\n","1007/1007 [==============================] - 1s 779us/step - loss: 9.1522e-05\n","##**~~__ Autoencoder 5/26 for 5 dimensions\n","1007/1007 [==============================] - 1s 817us/step - loss: 0.0012\n","##**~~__ Autoencoder 6/26 for 3 dimensions\n","1007/1007 [==============================] - 1s 786us/step - loss: 0.2127\n","##**~~__ Autoencoder 7/26 for 1 dimensions\n","1007/1007 [==============================] - 1s 730us/step - loss: 0.2534\n","##**~~__ Autoencoder 8/26 for 10 dimensions\n","1007/1007 [==============================] - 1s 838us/step - loss: 0.0015\n","##**~~__ Autoencoder 9/26 for 8 dimensions\n","1007/1007 [==============================] - 1s 796us/step - loss: 0.0309\n","##**~~__ Autoencoder 10/26 for 1 dimensions\n","1007/1007 [==============================] - 1s 734us/step - loss: 8.9213e-04\n","##**~~__ Autoencoder 11/26 for 2 dimensions\n","1007/1007 [==============================] - 1s 810us/step - loss: 1.9973e-04\n","##**~~__ Autoencoder 12/26 for 1 dimensions\n","1007/1007 [==============================] - 1s 732us/step - loss: 0.0232\n","##**~~__ Autoencoder 13/26 for 1 dimensions\n","1007/1007 [==============================] - 1s 749us/step - loss: 0.0403\n","##**~~__ Autoencoder 14/26 for 1 dimensions\n","1007/1007 [==============================] - 1s 750us/step - loss: 0.0107\n","##**~~__ Autoencoder 15/26 for 5 dimensions\n","1007/1007 [==============================] - 1s 786us/step - loss: 6.9627e-04\n","##**~~__ Autoencoder 16/26 for 9 dimensions\n","1007/1007 [==============================] - 1s 876us/step - loss: 0.0463\n","##**~~__ Autoencoder 17/26 for 8 dimensions\n","1007/1007 [==============================] - 1s 854us/step - loss: 7.2172e-04\n","##**~~__ Autoencoder 18/26 for 5 dimensions\n","1007/1007 [==============================] - 1s 816us/step - loss: 0.0094\n","##**~~__ Autoencoder 19/26 for 1 dimensions\n","1007/1007 [==============================] - 1s 757us/step - loss: 0.0147\n","##**~~__ Autoencoder 20/26 for 1 dimensions\n","1007/1007 [==============================] - 1s 746us/step - loss: 0.0144\n","##**~~__ Autoencoder 21/26 for 5 dimensions\n","1007/1007 [==============================] - 1s 810us/step - loss: 0.0133\n","##**~~__ Autoencoder 22/26 for 2 dimensions\n","1007/1007 [==============================] - 1s 799us/step - loss: 0.0076\n","##**~~__ Autoencoder 23/26 for 4 dimensions\n","1007/1007 [==============================] - 1s 806us/step - loss: 0.0040\n","##**~~__ Autoencoder 24/26 for 8 dimensions\n","1007/1007 [==============================] - 1s 818us/step - loss: 0.0083\n","##**~~__ Autoencoder 25/26 for 4 dimensions\n","1007/1007 [==============================] - 1s 796us/step - loss: 0.0049\n","##**~~__ Autoencoder 26/26 for 10 dimensions\n","1007/1007 [==============================] - 1s 816us/step - loss: 0.0204\n","##**~~__ Output Autoencoder for 26 dimensions\n","1007/1007 [==============================] - 1s 1ms/step - loss: 6.5919e-04\n"]}],"metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-28T16:46:56.388161Z","iopub.execute_input":"2021-06-28T16:46:56.388427Z","iopub.status.idle":"2021-06-28T16:47:28.059044Z","shell.execute_reply.started":"2021-06-28T16:46:56.388401Z","shell.execute_reply":"2021-06-28T16:47:28.058096Z"},"trusted":true}},{"cell_type":"code","execution_count":10,"source":["test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5]\n","\n","for i, x in enumerate(test_data):\n","    print(i)\n","    print(f\"Shape of data: {x.shape}\")\n","    outcome = ensemble.predict(x)\n","    print(f\"Detected anomalies: {np.mean(outcome)*100}%\")\n","    print()"],"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","Shape of data: (9548, 115)\n","Detected anomalies: 0.6388772517804776%\n","\n","1\n","Shape of data: (107685, 115)\n","Detected anomalies: 100.0%\n","\n","2\n","Shape of data: (102195, 115)\n","Detected anomalies: 100.0%\n","\n","3\n","Shape of data: (122573, 115)\n","Detected anomalies: 100.0%\n","\n","4\n","Shape of data: (237665, 115)\n","Detected anomalies: 100.0%\n","\n","5\n","Shape of data: (81982, 115)\n","Detected anomalies: 100.0%\n","\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-06-28T16:47:28.060094Z","iopub.execute_input":"2021-06-28T16:47:28.060334Z","iopub.status.idle":"2021-06-28T16:47:31.091858Z","shell.execute_reply.started":"2021-06-28T16:47:28.060310Z","shell.execute_reply":"2021-06-28T16:47:31.090912Z"},"trusted":true}}]}